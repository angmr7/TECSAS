{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system('pip install -q glob2==0.7 requests pytest-shutil==1.7.0 pyBigWig urllib3==1.26.14 tqdm==4.64.1 joblib==1.2.0 ipywidgets==8.0.4 biopython')"
      ],
      "metadata": {
        "id": "wgqwffpoNaej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r TECSAS/\n",
        "!git clone https://github.com/ed29rice/TECSAS.git"
      ],
      "metadata": {
        "id": "JBDVPTnGNSj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import TECSAS.TECSAS as TECSAS"
      ],
      "metadata": {
        "id": "XiwtfGWONXwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dpath='/content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/'"
      ],
      "metadata": {
        "id": "7uQjyh8hExjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/K562_GRCh38_zscore_all.zip\n",
        "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/H1_GRCh38_zscore_all.zip\n",
        "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/HCT116_GRCh38_zscore_all.zip\n",
        "!unzip /content/drive/MyDrive/TECSAS/XADs_HistMod_RNASeq/IMR-90_GRCh38_zscore_all.zip"
      ],
      "metadata": {
        "id": "U5WsufbMNisV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict only using Histone Modifications ChIP-Seq and RNASeq experiments"
      ],
      "metadata": {
        "id": "18ZUSdVgTsEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./K562_GRCh38_zscore_all/unique_exp.txt ./K562_GRCh38_zscore_all/_unique_exp.txt\n",
        "!echo H2AFZ >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27ac >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K36me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me1 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me2 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K79me2 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9ac >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9me3 >> ./K562_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H4K20me1 >> ./K562_GRCh38_zscore_all/unique_exp.txt"
      ],
      "metadata": {
        "id": "o6rDMWVYSMe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./H1_GRCh38_zscore_all/unique_exp.txt ./H1_GRCh38_zscore_all/_unique_exp.txt\n",
        "!echo H2AFZ >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27ac >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K36me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me1 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me2 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K79me2 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9ac >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9me3 >> ./H1_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H4K20me1 >> ./H1_GRCh38_zscore_all/unique_exp.txt"
      ],
      "metadata": {
        "id": "BPBTCY_lSUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./HCT116_GRCh38_zscore_all/unique_exp.txt ./HCT116_GRCh38_zscore_all/_unique_exp.txt\n",
        "!echo H2AFZ >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27ac >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K36me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me1 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me2 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K79me2 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9ac >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9me3 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H4K20me1 >> ./HCT116_GRCh38_zscore_all/unique_exp.txt"
      ],
      "metadata": {
        "id": "4fk-XsX_SUFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./IMR-90_GRCh38_zscore_all/unique_exp.txt ./IMR-90_GRCh38_zscore_all/_unique_exp.txt\n",
        "!echo H2AFZ >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27ac >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K27me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K36me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me1 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me2 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K4me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K79me2 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9ac >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H3K9me3 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt\n",
        "!echo H4K20me1 >> ./IMR-90_GRCh38_zscore_all/unique_exp.txt"
      ],
      "metadata": {
        "id": "uE2fsJeMSZiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyy38ljoNFhZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import math\n",
        "import os, sys\n",
        "import copy\n",
        "import time\n",
        "import seaborn as sns\n",
        "from typing import Tuple\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import dataset\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib.colors import LogNorm\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "class MidpointNormalize(colors.Normalize):\n",
        "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
        "        self.midpoint = midpoint\n",
        "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
        "\n",
        "    def __call__(self, value, clip=None):\n",
        "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
        "        # simple example...\n",
        "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
        "        return np.ma.masked_array(np.interp(value, x, y))\n",
        "\n",
        "def get_batch(source: Tensor, i: int, n_predict: int) -> Tuple[Tensor, Tensor]:\n",
        "    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n",
        "    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n",
        "    return data.to(device), target.to(device)\n",
        "\n",
        "def get_batch_test(source: Tensor, i: int, n_predict: int, ndxs ) -> Tuple[Tensor, Tensor]:\n",
        "    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n",
        "    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n",
        "    if ndxs is not None:\n",
        "        indexes = ndxs[i*bptt:(i+1)*bptt]\n",
        "    else:\n",
        "        indexes = None\n",
        "    return data.to(device), target.to(device), indexes\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    src_mask = None\n",
        "\n",
        "    bs=list(range(nbatches))\n",
        "    np.random.shuffle(bs)\n",
        "    count=0\n",
        "    for batch in bs:\n",
        "        if count%100==0:print('Batch ',count, ' out of ',nbatches,end='\\r')\n",
        "        count+=1\n",
        "        i=batch\n",
        "        data, targets = get_batch(train_data, i, n_predict=n_predict)\n",
        "        output, output_tf = model(data, src_mask)\n",
        "        loss = 0\n",
        "        for n in range(2*(n_predict-1)+1):\n",
        "            loss += criterion(output[:,n], targets[:,n].type(torch.LongTensor).to(device))\n",
        "        data.detach()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        total_loss = total_loss + loss.item()\n",
        "    return total_loss\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor, type='test') -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = None\n",
        "    nbatches_eval=len(eval_data)//bptt\n",
        "    with torch.no_grad():\n",
        "        for batch in range(nbatches_eval):\n",
        "            data, targets = get_batch(eval_data, batch, n_predict=n_predict)\n",
        "            output, output_tf = model(data, src_mask)\n",
        "            for n in range(2*(n_predict-1)+1):\n",
        "                total_loss += criterion(output[:,n], targets[:,n].type(torch.LongTensor).to(device)).item()\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the type of XAD\n",
        "typeN='LADS'"
      ],
      "metadata": {
        "id": "BbE3h6IqUUYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEXP = 11\n",
        "dpath='./results_w'+str(NEXP)\n",
        "try:\n",
        "    os.mkdir(dpath)\n",
        "except:\n",
        "    print('Directory already created')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "n_neigbors = 14\n",
        "n_predict = 3\n",
        "nbatches = 200\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "cell='K562'\n",
        "pymb=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/K562_'+typeN+'/',\n",
        "            signal_type='signal p-value',ref_cell_line_path='./K562_GRCh38_zscore_all', cell_line_path='./K562_GRCh38_zscore_all',\n",
        "            histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
        "\n",
        "pymb.ref_chrm_size=pymb.chrm_size\n",
        "train_set,val_set,test_set,all_averages,loci_indx=pymb.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
        "                                        n_predict=n_predict)\n",
        "\n",
        "if typeN!='SPECKLES':\n",
        "    cell='H1'\n",
        "    pymb_h1=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/H1_'+typeN+'',\n",
        "                signal_type='signal p-value',ref_cell_line_path='./H1_GRCh38_zscore_all', cell_line_path='./H1_GRCh38_zscore_all',\n",
        "                histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
        "\n",
        "    pymb_h1.ref_chrm_size=pymb_h1.chrm_size\n",
        "    train_set_h1,val_set_h1,test_set_h1,all_averages_h1,loci_indx_h1=pymb_h1.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
        "                                            n_predict=n_predict)\n",
        "\n",
        "    cell='HCT116'\n",
        "    pymb_hc=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/HCT116_'+typeN+'',\n",
        "                signal_type='signal p-value',ref_cell_line_path='./HCT116_GRCh38_zscore_all', cell_line_path='./HCT116_GRCh38_zscore_all',\n",
        "                histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
        "\n",
        "    pymb_hc.ref_chrm_size=pymb_hc.chrm_size\n",
        "    train_set_hc,val_set_hc,test_set_hc,all_averages_hc,loci_indx_hc=pymb_hc.training_data(n_neigbors=n_neigbors,train_per=0.8,\n",
        "                                            n_predict=n_predict)\n",
        "\n",
        "    all_averages=np.concatenate([all_averages_hc,all_averages_h1,all_averages],axis=1)\n",
        "    train_set=np.concatenate([train_set_hc,train_set_h1,train_set],axis=0)\n",
        "    val_set=np.concatenate([val_set_hc,val_set_h1,val_set],axis=0)\n",
        "    test_set=np.concatenate([test_set_hc,test_set_h1,test_set],axis=0)\n",
        "    loci_indx=np.concatenate([loci_indx_hc,loci_indx_h1,loci_indx],axis=0)\n",
        "\n",
        "train_data=torch.tensor(train_set,dtype=torch.float)\n",
        "val_data=torch.tensor(val_set,dtype=torch.float)\n",
        "test_data=torch.tensor(test_set,dtype=torch.float)\n",
        "print(train_data.size(),val_data.size(),test_data.size())\n"
      ],
      "metadata": {
        "id": "Wa5SKnvRNLXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.load('results_w11/params_bv_11.pt')\n",
        "\n",
        "new_params = {}\n",
        "for key, value in params.items():\n",
        "    new_key = key.split('module.')[1]\n",
        "    new_params[new_key] = value\n",
        "\n",
        "torch.save(new_params, 'results_w11/modified_params_bv_11.pt')\n"
      ],
      "metadata": {
        "id": "Gc6o0TZXGCYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "bptt = len(train_data)//nbatches\n",
        "print('Size of batch:',bptt)\n",
        "\n",
        "emsize = 128 # embedding dimension\n",
        "d_hid = 64 # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 8  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.01  # dropout probability\n",
        "nfeatures = train_data.size()[1]-(2*(n_predict-1)+1)\n",
        "ostates = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = TECSAS.TECSAS(n_predict, emsize, nhead, d_hid, nlayers, nfeatures, ostates, dropout).to(device)\n",
        "#Load encoder layer from GM12878 training session\n",
        "model.load_state_dict(torch.load(dpath+'/modified_params_bv_11.pt'))\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "#Modify architecture to predict 2 classes (XAD/nonXAD) instead of 5\n",
        "model.unfl = nn.Unflatten(-1,((2*(n_predict-1)+1),2))\n",
        "model.l2 = nn.Linear(nfeatures*emsize,2*(2*(n_predict-1)+1))\n",
        "initrange = 0.1\n",
        "model.l2.bias.data.zero_()\n",
        "model.l2.weight.data.uniform_(-initrange, initrange)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qc3OvqMCTEOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(model.modules)\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print('Number of params:',params)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_train_loss = float('inf')\n",
        "epochs = 30\n",
        "nepochs = 100\n",
        "\n",
        "lr = 2.5  # learning rate\n",
        "optimizer = torch.optim.SGD(model.l2.parameters(), lr=lr)\n",
        "\n",
        "bsteps=0\n",
        "vlosses=[]\n",
        "for epoch in range(1, epochs + 1):\n",
        "    if epoch%nepochs==1:\n",
        "        print('Reseting lr')\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr,weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5)\n",
        "        train_loss=train(model)\n",
        "    lr_e = scheduler.get_last_lr()[0]\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss=train(model)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    val_loss = evaluate(model, val_data, type='val')\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "        f'valid loss {val_loss:5.2f} | train loss {train_loss:5.2f} | lr {lr_e:2.5f} | best val loss: {best_val_loss:5.2f}')\n",
        "    print('-' * 89)\n",
        "    vlosses.append(val_loss)\n",
        "    if train_loss < best_train_loss:\n",
        "        print('Found better train_loss')\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), dpath+'/best_train_model_params_'+typeN+'.pt')\n",
        "        bsteps=bsteps+2\n",
        "    if val_loss < best_val_loss:\n",
        "        print('Found better val_loss')\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), dpath+'/best_val_model_params_'+typeN+'.pt')\n",
        "    else:\n",
        "        bsteps=bsteps+1\n",
        "    if bsteps>5:\n",
        "        print('Has not found better train_loss in 5 epochs, reducing lr')\n",
        "        scheduler.step()\n",
        "        print(scheduler.get_last_lr()[0])\n",
        "        bsteps=0\n",
        "print('=' * 89)\n",
        "print(f'| End of training | best val loss {best_val_loss:5.2f} | ')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(list(range(1, epochs + 1)),vlosses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Val loss')\n",
        "plt.title(typeN+' training')\n",
        "plt.savefig(dpath+'/vloss_'+typeN+'.png')"
      ],
      "metadata": {
        "id": "tFVOnuH8TV4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "f=0\n",
        "for p in ['best_val']:\n",
        "    print(p)\n",
        "    model.load_state_dict(torch.load(dpath+'/'+p+'_model_params_'+typeN+'.pt'))\n",
        "    nbatches_eval=len(test_data)//bptt\n",
        "    l=[]\n",
        "    lt=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in range(nbatches_eval):\n",
        "            data, targets, _ = get_batch_test(test_data, batch, n_predict=n_predict, ndxs = None)\n",
        "            prediction = model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n",
        "            l.append(prediction)\n",
        "            lt.append(targets[:,n_predict-1].cpu())\n",
        "    l=np.concatenate(l)\n",
        "    lt=np.concatenate(lt)\n",
        "    print('test:',np.round(np.sum(l==lt)/len(l),4))\n",
        "\n",
        "    conf_matrix_P=np.round(confusion_matrix(l,lt,normalize='true'),2)\n",
        "    print('BT Confusion matrix:')\n",
        "    print(conf_matrix_P)"
      ],
      "metadata": {
        "id": "AfPtORSMTSam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict XAD for IMR-90\n",
        "cell='IMR-90'\n",
        "pymb=TECSAS.data_process(cell_line=cell, assembly='GRCh38', organism='human',types_path='./TECSAS/TECSAS/share/K562_'+typeN+'/',\n",
        "            signal_type='signal p-value',ref_cell_line_path='./IMR-90_GRCh38_zscore_all', cell_line_path='./IMR-90_GRCh38_zscore_all',\n",
        "            histones=True,tf=False,small_rna=False,total_rna=False,n_states=10,res=50)\n",
        "\n",
        "pymb.ref_chrm_size=pymb.chrm_size\n",
        "test_set,all_averages=pymb.test_data(n_neigbors=n_neigbors,n_predict=n_predict)\n",
        "\n",
        "all_loci = np.array(list(range(len(all_averages[0]))))\n",
        "ntest_loci = all_loci\n",
        "test_data=torch.tensor(test_set,dtype=torch.float)\n",
        "print(test_data.size())\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "bptt = 10\n",
        "print('Size of batch:',bptt)"
      ],
      "metadata": {
        "id": "s_mV5e-oYvey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "f=0\n",
        "for p in ['best_val']:\n",
        "    print(p)\n",
        "    model.load_state_dict(torch.load(dpath+'/'+p+'_model_params_'+typeN+'.pt'))\n",
        "    nbatches_eval=len(test_data)//bptt\n",
        "    l=[]\n",
        "    lt=[]\n",
        "    loci=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in range(nbatches_eval):\n",
        "            data, targets, batch_loci = get_batch_test(test_data, batch, n_predict=n_predict, ndxs = ntest_loci)\n",
        "            prediction=model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n",
        "            loci.append(batch_loci)\n",
        "            l.append(prediction)\n",
        "            lt.append(targets[:,n_predict-1].cpu())\n",
        "    loci=np.concatenate(loci)\n",
        "    l=np.concatenate(l)\n",
        "    lt=np.concatenate(lt)\n",
        "\n"
      ],
      "metadata": {
        "id": "SZDwGT5rhLqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save a bed file with predictions\n",
        "info = {\n",
        "    0: ('1', \"245,47,47\"),\n",
        "    1: ('4', \"47,47,224\"),\n",
        "    \"NA\": (0, \"255,255,255\"),\n",
        "    \"A1\": (1, \"245,47,47\"),\n",
        "    \"A2\": (2, \"145,47,47\"),\n",
        "    \"B1\": (3, \"47,187,224\"),\n",
        "    \"B2\": (4, \"47,47,224\"),\n",
        "    \"B3\": (5, \"47,47,139\"),\n",
        "    \"B4\": (6, \"75,0,130\"),\n",
        "    \"A\": (1, \"245,47,47\"),\n",
        "    \"B\": (2, \"47,187,224\"),\n",
        "    }\n",
        "\n",
        "offset=0\n",
        "print(np.sum(pymb.chrm_size[:22]),np.max(ntest_loci),np.max(loci))\n",
        "cid=0\n",
        "tmpc=pymb.chrm_size[cid]\n",
        "loci=loci+14\n",
        "with open(dpath+'/'+typeN+'_IMR-90.txt','w') as f:\n",
        "    for i in range(len(loci)):\n",
        "        if loci[i]-offset>tmpc-1:\n",
        "            offset=loci[i]\n",
        "            cid=cid+1\n",
        "            tmpc=pymb.chrm_size[cid]\n",
        "        chromosome=cid+1\n",
        "        position=loci[i]-offset\n",
        "        resolution=50000\n",
        "        text=\"chr\" + str(chromosome) + \"\\t\" + str((position - 1) * resolution) + \"\\t\"\n",
        "        text=text+str(position * resolution) + \"\\t\" + str(l[i]) + \"\\t\" + info[l[i]][0] + \"\\t.\\t\"\n",
        "        text=text+str((position - 1) * resolution) + \"\\t\" + str(position * resolution) + \"\\t \" + info[l[i]][1]\n",
        "        f.write(text+'\\n')\n",
        "print(np.unique(l,return_counts=True))\n"
      ],
      "metadata": {
        "id": "6d2qULbziJVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}