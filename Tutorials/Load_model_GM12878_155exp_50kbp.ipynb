{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NDjmyKDNi9vz"},"outputs":[],"source":["import os\n","os.system('pip install -q glob2==0.7 requests pytest-shutil==1.7.0 pyBigWig urllib3==1.26.14 tqdm==4.64.1 joblib==1.2.0 ipywidgets==8.0.4 biopython')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kC3g5hLi_Uf"},"outputs":[],"source":["!rm -r TECSAS/\n","!git clone https://github.com/ed29rice/TECSAS.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShVGVF5lrgmV"},"outputs":[],"source":["import TECSAS.TECSAS as TECSAS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKS2xWrTjWLs"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LogNorm\n","import matplotlib.colors as colors\n","from tempfile import TemporaryDirectory\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import dataset\n","from torch.nn import functional as F\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_E6BBGxnFi8"},"outputs":[],"source":["#Path to training data and model parameters\n","dpath='./'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zaDk9Eoi_Xc"},"outputs":[],"source":["n_neigbors = 14\n","n_predict = 3\n","NEXP=155\n","nbatches = 4000\n","\n","emsize = 128 # embedding dimension\n","d_hid = 64 # dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 8  # number of heads in nn.MultiheadAttention\n","dropout = 0.01  # dropout probability\n","nfeatures = NEXP*(2*n_neigbors+1)\n","ostates = 5\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = TECSAS.TECSAS(n_predict, emsize, nhead, d_hid, nlayers, nfeatures, ostates, dropout).to(device)\n","\n","model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print('Number of params:',params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXaEcWEtjXaO"},"outputs":[],"source":["dict_p=torch.load(dpath+'/bv_GM12878_155.pt',map_location=torch.device('cpu'))\n","tmp_dict={}\n","for k in dict_p.keys():\n","    tmp_dict['.'.join(k.split('.')[1:])]=dict_p[k]\n","\n","model.load_state_dict(tmp_dict)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCDYtB6ftcKt"},"outputs":[],"source":["checkpoint = torch.load(dpath+'/training_info_set_155.pt')\n","epoch = checkpoint['epoch']\n","loss = checkpoint['best_val_loss']\n","train_data = checkpoint['train_data']\n","test_data = checkpoint['test_data']\n","ntest_loci = checkpoint['ntest_loci']\n","loci_indx = checkpoint['loci_indx']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XMoQh2HtwEd"},"outputs":[],"source":["model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyLVyGg3uiGd"},"outputs":[],"source":["def get_batch_test(source: Tensor, i: int, n_predict: int, ndxs=None ):\n","    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n","    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n","    indexes = ndxs[i*bptt:(i+1)*bptt]\n","    return data.to(device), target.to(device), indexes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nWkl2RiVtwG8"},"outputs":[],"source":["#Predict subcompartments for GM12878 at 50kbp\n","bptt = len(train_data)//nbatches\n","nbatches_eval=len(test_data)//bptt\n","l=[]\n","lt=[]\n","failed_inputs=[]\n","failed_targets=[]\n","failed_pred=[]\n","failed_loci=[]\n","suc_inputs=[]\n","suc_targets=[]\n","suc_pred=[]\n","suc_loci=[]\n","with torch.no_grad():\n","    for batch in range(nbatches_eval):\n","        data, targets, batch_loci = get_batch_test(test_data, batch,n_predict=n_predict, ndxs=ntest_loci)\n","        if batch%10==0: print(batch, nbatches_eval, len(targets))\n","        prediction=model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n","        idx=prediction!=targets[:,n_predict-1].cpu()\n","        failed_inputs.append(targets[idx,n_predict-1].cpu())\n","        failed_targets.append(data[idx].cpu())\n","        failed_pred.append(prediction[idx])\n","        failed_loci.append(batch_loci[idx])\n","        idx=prediction==targets[:,n_predict-1].cpu()\n","        suc_inputs.append(targets[idx,n_predict-1].cpu())\n","        suc_targets.append(data[idx].cpu())\n","        suc_pred.append(prediction[idx])\n","        suc_loci.append(batch_loci[idx])\n","        l.append(prediction)\n","        lt.append(targets[:,n_predict-1].cpu())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wUhUSuJ1xr6O"},"outputs":[],"source":["failed_inputs=np.concatenate(failed_inputs)\n","failed_pred=np.concatenate(failed_pred)\n","failed_targets=np.concatenate(failed_targets)\n","failed_loci=np.concatenate(failed_loci)\n","suc_inputs=np.concatenate(suc_inputs)\n","suc_pred=np.concatenate(suc_pred)\n","suc_targets=np.concatenate(suc_targets)\n","suc_loci=np.concatenate(suc_loci)\n","l=np.concatenate(l)\n","lt=np.concatenate(lt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nKfZPdILxwau"},"outputs":[],"source":["print('BT Accuracy:')\n","print('test:',np.round(np.sum(l==lt)/len(l),4))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gjwmhWcMxy7u"},"outputs":[],"source":["conf_matrix_P=np.round(confusion_matrix(l,lt,normalize='true'),2)\n","print('BT Confusion matrix:')\n","print(conf_matrix_P)\n","\n","conf_matrix_P=np.round(confusion_matrix(l>1,lt>1,normalize='true'),2)\n","print('AB Confusion matrix:')\n","print(conf_matrix_P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TB6nzaIr4NY"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNaXmF5vHPh10ZYg/IEHmJQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}