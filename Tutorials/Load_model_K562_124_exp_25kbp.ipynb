{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPfaOH3N0D37WE/S3mcJNZk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NDjmyKDNi9vz"},"outputs":[],"source":["import os\n","os.system('pip install -q glob2==0.7 requests pytest-shutil==1.7.0 pyBigWig==0.3.18 urllib3==1.26.14 tqdm==4.64.1 joblib==1.2.0 ipywidgets==8.0.4 biopython')"]},{"cell_type":"code","source":["!rm -r TECSAS/\n","!git clone https://github.com/ed29rice/TECSAS.git"],"metadata":{"id":"8kC3g5hLi_Uf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import TECSAS.TECSAS as TECSAS"],"metadata":{"id":"ShVGVF5lrgmV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LogNorm\n","import matplotlib.colors as colors\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.utils.data import dataset\n","from torch.nn import functional as F\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"yKS2xWrTjWLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Path to training data and model parameters\n","dpath='./'"],"metadata":{"id":"O_E6BBGxnFi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_neigbors = 14\n","n_predict = 3\n","NEXP = 124\n","nbatches = 8000\n","\n","emsize = 128 # embedding dimension\n","d_hid = 64 # dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 8  # number of heads in nn.MultiheadAttention\n","dropout = 0.01  # dropout probability\n","nfeatures = NEXP*(2*n_neigbors+1)\n","ostates = 5\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = TECSAS.TECSAS(n_predict, emsize, nhead, d_hid, nlayers, nfeatures, ostates, dropout).to(device)\n","\n","model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print('Number of params:',params)"],"metadata":{"id":"3zaDk9Eoi_Xc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_neigbors = 14\n","n_predict = 3\n","NEXP = 124\n","nbatches = 8000"],"metadata":{"id":"JSX7kvztQzT6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dict_p=torch.load(dpath+'/bv_K562_124.pt')\n","tmp_dict={}\n","for k in dict_p.keys():\n","    tmp_dict['.'.join(k.split('.')[1:])]=dict_p[k]\n","\n","model.load_state_dict(tmp_dict)\n","model.eval()"],"metadata":{"id":"SXaEcWEtjXaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NEXP=124\n","checkpoint = torch.load(dpath+'/training_info_set_124.pt')\n","epoch = checkpoint['epoch']\n","loss = checkpoint['best_val_loss']\n","train_data = checkpoint['train_data']\n","test_data = checkpoint['test_data']\n","ntest_loci = checkpoint['ntest_loci']\n","loci_indx = checkpoint['loci_indx']"],"metadata":{"id":"ZCDYtB6ftcKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])"],"metadata":{"id":"9XMoQh2HtwEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_batch_test(source: Tensor, i: int, n_predict: int, ndxs=None ):\n","    data = source[i*bptt:(i+1)*bptt,2*(n_predict-1)+1:][:,:,np.newaxis]\n","    target = source[i*bptt:(i+1)*bptt,:2*(n_predict-1)+1]\n","    indexes = ndxs[i*bptt:(i+1)*bptt]\n","    return data.to(device), target.to(device), indexes"],"metadata":{"id":"JyLVyGg3uiGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predicting subcompartments for K562 test set\n","bptt = len(train_data)//nbatches\n","nbatches_eval=len(test_data)//bptt\n","l=[]\n","lt=[]\n","failed_inputs=[]\n","failed_targets=[]\n","failed_pred=[]\n","failed_loci=[]\n","suc_inputs=[]\n","suc_targets=[]\n","suc_pred=[]\n","suc_loci=[]\n","with torch.no_grad():\n","    for batch in range(nbatches_eval):\n","        data, targets, batch_loci = get_batch_test(test_data, batch,n_predict=n_predict, ndxs=ntest_loci)\n","        if batch%10==0: print(batch, nbatches_eval, len(targets))\n","        prediction=model(data,None)[0].argmax(dim=-1)[:,n_predict-1].cpu()\n","        idx=prediction!=targets[:,n_predict-1].cpu()\n","        failed_inputs.append(targets[idx,n_predict-1].cpu())\n","        failed_targets.append(data[idx].cpu())\n","        failed_pred.append(prediction[idx])\n","        failed_loci.append(batch_loci[idx])\n","        idx=prediction==targets[:,n_predict-1].cpu()\n","        suc_inputs.append(targets[idx,n_predict-1].cpu())\n","        suc_targets.append(data[idx].cpu())\n","        suc_pred.append(prediction[idx])\n","        suc_loci.append(batch_loci[idx])\n","        l.append(prediction)\n","        lt.append(targets[:,n_predict-1].cpu())"],"metadata":{"id":"nWkl2RiVtwG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["failed_inputs=np.concatenate(failed_inputs)\n","failed_pred=np.concatenate(failed_pred)\n","failed_targets=np.concatenate(failed_targets)\n","failed_loci=np.concatenate(failed_loci)\n","suc_inputs=np.concatenate(suc_inputs)\n","suc_pred=np.concatenate(suc_pred)\n","suc_targets=np.concatenate(suc_targets)\n","suc_loci=np.concatenate(suc_loci)\n","l=np.concatenate(l)\n","lt=np.concatenate(lt)"],"metadata":{"id":"wUhUSuJ1xr6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('BT Accuracy:')\n","print('test:',np.round(np.sum(l==lt)/len(l),4))"],"metadata":{"id":"nKfZPdILxwau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conf_matrix_P=np.round(confusion_matrix(l,lt,normalize='true'),2)\n","print('BT Confusion matrix:')\n","print(conf_matrix_P)"],"metadata":{"id":"gjwmhWcMxy7u"},"execution_count":null,"outputs":[]}]}